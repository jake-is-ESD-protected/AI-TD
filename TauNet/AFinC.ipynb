{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "General imports and loading of the audio file for development and explorative research.\n",
    "The audio signal is normalized in the time domain to its highest value.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import os\n",
    "import taunet_utils\n",
    "%run transient_shaper_lib.ipynb\n",
    "\n",
    "SAMPLE_LENGTH = 10\n",
    "\n",
    "audio_data_with_labels = taunet_utils.read_audio_files(os.getcwd(), truncate_at=SAMPLE_LENGTH)\n",
    "\n",
    "print(\"Audio data and labels:\")\n",
    "for audio_data, label, sample_rate in audio_data_with_labels:\n",
    "  print(f\"- Label: {label}, Audio data shape: {audio_data.shape}, Sample rate: {sample_rate}\")\n",
    "\n",
    "FRAME_LEN = 1   # in s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleRate = 96000\n",
    "BEAT_DETECTION_BUFFER_SIZE = 64\n",
    "AUDIO_BUFFER_SIZE_S = 8\n",
    "AUDIO_BUFFER_SIZE = sampleRate * AUDIO_BUFFER_SIZE_S\n",
    "MAX_ONSETS = 4 * AUDIO_BUFFER_SIZE_S # 4 BPS IS 240 BPM\n",
    "\n",
    "\n",
    "from ctypes import *\n",
    "from typing import Literal\n",
    "lib = CDLL(\"../src/af/AFInC.dll\")  # Adjust path accordingly\n",
    "\n",
    "lib.resetBuffer.argtypes = []\n",
    "lib.resetBuffer.restype = None\n",
    "\n",
    "lib.initAf.argtypes = []\n",
    "lib.initAf.restype = None\n",
    "\n",
    "lib.AFInCAppend.argtypes = [c_double]\n",
    "lib.AFInCAppend.restype = None\n",
    "\n",
    "lib.AFInCProcess.argtypes = []\n",
    "lib.AFInCProcess.restype = None\n",
    "\n",
    "lib.afGetT1A.argtypes = []\n",
    "lib.afGetT1A.restype = c_double\n",
    "\n",
    "lib.afGetT2A.argtypes = []\n",
    "lib.afGetT2A.restype = c_double\n",
    "\n",
    "lib.afGetTempo.argtypes = []\n",
    "lib.afGetTempo.restype = c_double\n",
    "\n",
    "lib.afGetSpectralCentroid.argtypes = []\n",
    "lib.afGetSpectralCentroid.restype = c_double\n",
    "\n",
    "lib.afGetSpectralFlatness.argtypes = []\n",
    "lib.afGetSpectralFlatness.restype = c_double\n",
    "\n",
    "lib.afGetPBandL.argtypes = []\n",
    "lib.afGetPBandL.restype = c_double\n",
    "\n",
    "lib.afGetPBandML.argtypes = []\n",
    "lib.afGetPBandML.restype = c_double\n",
    "\n",
    "lib.afGetPBandMH.argtypes = []\n",
    "lib.afGetPBandMH.restype = c_double\n",
    "\n",
    "lib.afGetPBandH.argtypes = []\n",
    "lib.afGetPBandH.restype = c_double\n",
    "\n",
    "lib.afGetCrestFactor.argtypes = []\n",
    "lib.afGetCrestFactor.restype = c_double\n",
    "\n",
    "lib.afGetSpectralFlux.argtypes = []\n",
    "lib.afGetSpectralFlux.restype = c_double\n",
    "\n",
    "# ----------------------------------------\n",
    "# debug helpers\n",
    "# ----------------------------------------\n",
    "lib.__getAudioBuffer.argtypes = []\n",
    "lib.__getAudioBuffer.restype = c_double\n",
    "\n",
    "lib.__getEnvBuffer.argtypes = []\n",
    "lib.__getEnvBuffer.restype = c_double\n",
    "\n",
    "lib.__getOnsetBuffer.argtypes = []\n",
    "lib.__getOnsetBuffer.restype = c_double\n",
    "\n",
    "lib.__getTA1Buffer.argtypes = []\n",
    "lib.__getTA1Buffer.restype = c_double\n",
    "\n",
    "lib.__getTA2Buffer.argtypes = []\n",
    "lib.__getTA2Buffer.restype = c_double\n",
    "\n",
    "lib.__getBeatMagnitude.argtypes = [c_int]\n",
    "lib.__getBeatMagnitude.restype = c_double\n",
    "\n",
    "lib.__resetIndexDebug.argtypes = []\n",
    "lib.__resetIndexDebug.restype = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for song in audio_data_with_labels:\n",
    "    lib.__resetIndexDebug()\n",
    "\n",
    "    target_device_audio_buffer = []\n",
    "    envelope = []\n",
    "    onsets = []\n",
    "    TA1Buffer = []\n",
    "    TA2Buffer = []\n",
    "    magnitudePerBeat = np.zeros((512 * MAX_ONSETS // 512, 512))\n",
    "    lib.initAf()\n",
    "    lib.resetBuffer()\n",
    "\n",
    "    print(song[1])\n",
    "    for sample in song[0]:\n",
    "        lib.AFInCAppend(sample)\n",
    "\n",
    "    lib.AFInCProcess()\n",
    "    \n",
    "    print(\"--- AF in C features ---\")\n",
    "    print(\"Tempo: \", lib.afGetTempo())\n",
    "    print(\"TA1: \", lib.afGetT1A() / sample_rate)\n",
    "    print(\"TA2: \", lib.afGetT2A() / sample_rate)\n",
    "    print(\"Spectral centroid:\", int(lib.afGetSpectralCentroid()), \"Hz\")\n",
    "    print(\"Spectral flatness:\", lib.afGetSpectralFlatness())\n",
    "    print(\"EQ Low: \", int(lib.afGetPBandL()), \"\")\n",
    "    print(\"EQ MidLow: \", int(lib.afGetPBandML()), \"\")\n",
    "    print(\"EQ MidHigh: \", int(lib.afGetPBandMH()), \"\")\n",
    "    print(\"EQ High: \", int(lib.afGetPBandH()), \"\")\n",
    "    print(\"Crest Factor:\", lib.afGetCrestFactor())\n",
    "    print(\"Spectral Flux: \", lib.afGetSpectralFlux())\n",
    "    print(\"-------\")\n",
    "    \n",
    "    for sample in song[0]:\n",
    "        target_device_audio_buffer.append(lib.__getAudioBuffer())\n",
    "        envelope.append(lib.__getEnvBuffer())\n",
    "    \n",
    "    for onset in range(MAX_ONSETS):\n",
    "        currentOnset = lib.__getOnsetBuffer()\n",
    "        if(currentOnset == 0):\n",
    "            break\n",
    "        currentTA1 = lib.__getTA1Buffer() / sample_rate\n",
    "        curretnTA2 = lib.__getTA2Buffer() / sample_rate\n",
    "        onsets.append(currentOnset)\n",
    "        TA1Buffer.append(currentTA1)\n",
    "        TA2Buffer.append(curretnTA2)\n",
    "\n",
    "    print(\"TA1 python percentile: \", np.percentile(TA1Buffer, 75))\n",
    "    print(\"TA2 python percentile:: \", np.percentile(TA2Buffer, 75))\n",
    "    print(len(magnitudePerBeat))\n",
    "    for perBeat, value in enumerate(onsets):\n",
    "        for bin in range(0,512):\n",
    "            magnitudePerBeat[perBeat,bin] = lib.__getBeatMagnitude(perBeat)\n",
    "\n",
    "    print(np.shape(magnitudePerBeat))\n",
    "    plt.figure(figsize=(30, 12))\n",
    "    ax = plt.gca()  # Get the current axes for customization\n",
    "    ax.xaxis.set_major_locator(ticker.LinearLocator(numticks=50))\n",
    "\n",
    "    plt.plot([i/sampleRate for i in range(len(song[0]))], song[0], label=\"Python audio\")\n",
    "    plt.plot([i/sampleRate for i in range(len(target_device_audio_buffer))], target_device_audio_buffer, alpha=0.7, label=\"C Audio\")\n",
    "    plt.plot([i/sampleRate for i in range(len(envelope))], envelope, label=\"Envelope\")\n",
    "    for i, onset in enumerate(onsets):\n",
    "        if int(onset) != 0:\n",
    "            if i == 0:\n",
    "                plt.axvline(x=int(onset)/sampleRate, color='r', linestyle='--', label=\"Onsets (compensated)\")\n",
    "            else:\n",
    "                plt.axvline(x=int(onset)/sampleRate, color='r', linestyle='--')\n",
    "        \n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    for spec in magnitudePerBeat:\n",
    "        if np.mean(spec) != 0:\n",
    "            n = len(spec)\n",
    "            freq = np.arange(0, sample_rate / 2, sample_rate / n / 2)\n",
    "            plt.figure()\n",
    "            plt.grid()\n",
    "            plt.semilogx(freq, spec)\n",
    "            plt.xlabel('Frequency (Hz)')\n",
    "            plt.ylabel('Magnitude')\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load your audio file\n",
    "filename = 'untitled.wav'\n",
    "y, sr = librosa.load(filename, sr=96000)  # Specify the 96kHz sample rate\n",
    "\n",
    "# Calculate spectral centroid\n",
    "spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)[0]\n",
    "\n",
    "# Let's visualize how the spectral centroid changes over time\n",
    "frames = range(len(spectral_centroid))\n",
    "t = librosa.frames_to_time(frames)\n",
    "\n",
    "# Plot the spectral centroid \n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(t, spectral_centroid)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Spectral Centroid (Hz)')\n",
    "plt.title('Spectral Centroid over Time')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
