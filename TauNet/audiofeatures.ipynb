{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audiofeatures for AI-TD\n",
    "We need a more or less big feature vector directly derived from a recorded waveform. To be specific, we want the audiofeatures of a **1 s** frame from a recording which may have any length between **1** and **5** seconds. After that, we can take the mean of all these frames. Some features may be linked to a peak in the signal or output an array which can be averaged. As it stands, we only want scalar values for each feature per frame, which after averaging also means one value per recording, making the inputs for the neural net easy to handle. The features are listed here and described and commputed below:\n",
    "\n",
    "- $T_{1A}$ : Analytical time constant of rise time of the most significant event in frame.\n",
    "- $T_{2A}$ : Analytical time constant of fall time of the most significant event in frame.\n",
    "- $G_{1H}$ : Attack-gain setting.\n",
    "- $G_{2H}$ : Sustain-gain setting.\n",
    "- $F_e$ : Spectral Flattness.\n",
    "- $C_f$ : Crest Factor.\n",
    "- $S_c$ : Spectral centroid.\n",
    "- $BPM$ : Beats per minute (beat detection).\n",
    "- $P_{band}$ : 4 band EQ, Multiplikation im Spektrum\n",
    "\n",
    "*Abbreviations:*  \n",
    "*$H$* : human-generated  \n",
    "*$A$* : analytically generated  \n",
    "\n",
    "The audiofeatures computed below are purposefully **NOT** pythonic, because they have to be ported into C/C++ for an embedded system and writing them C-like makes that process easier, as we do not rely on magic library functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kriso\\AppData\\Local\\Temp\\ipykernel_10220\\1147491842.py:30: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sample_rate, audio_data = sp.io.wavfile.read(filepath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio data and labels:\n",
      "- Label: 1 - looperman-l-5151565-0354397-spicy-drums, Audio data shape: (441000,), Sample rate: 44100\n",
      "- Label: 10 - 484656__yellowtree__gloomy-guitar-loop, Audio data shape: (480000,), Sample rate: 48000\n",
      "- Label: 11 - Vocal A, Audio data shape: (351744,), Sample rate: 44100\n",
      "- Label: 12 - Vocal B, Audio data shape: (441000,), Sample rate: 44100\n",
      "- Label: 13 - 20240208_Eli Preiss - Alles (und nichts) ｜ A COLORS SHOW, Audio data shape: (480000,), Sample rate: 48000\n",
      "- Label: 2 - looperman-l-2379402-0354276-aftershock-hard-trap-drums-x-808-x-percs-kb, Audio data shape: (441000,), Sample rate: 44100\n",
      "- Label: 3 - looperman-l-3066414-0354301-boom-bap-classic-hip-hop-drums, Audio data shape: (441000,), Sample rate: 44100\n",
      "- Label: 4 - 244392__insidebeat__hip-hop-3-mpc500, Audio data shape: (348923,), Sample rate: 44100\n",
      "- Label: 5 - 345289__50fps__4-beat-14-upbeat, Audio data shape: (195049,), Sample rate: 44100\n",
      "- Label: 6 - 367962__trngle__175bpm-db-drum-sequence, Audio data shape: (287981,), Sample rate: 44100\n",
      "- Label: 7 - 330744__alonnaallen__90s-beat-loop-140bpm, Audio data shape: (441000,), Sample rate: 44100\n",
      "- Label: 8 - 652462__yellowtree__midwest-clean-guitar, Audio data shape: (441000,), Sample rate: 44100\n",
      "- Label: 9 - 584282__yellowtree__clean-guitar-loop, Audio data shape: (960000,), Sample rate: 96000\n",
      "- Label: bass, Audio data shape: (423360,), Sample rate: 44100\n",
      "- Label: congas_82_25_1, Audio data shape: (441000,), Sample rate: 44100\n",
      "- Label: congas_82_25_5, Audio data shape: (441000,), Sample rate: 44100\n",
      "- Label: shaker, Audio data shape: (425216,), Sample rate: 44100\n",
      "- Label: single notes hoch, Audio data shape: (441000,), Sample rate: 44100\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "General imports and loading of the audio file for development and explorative research.\n",
    "The audio signal is normalized in the time domain to its highest value.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%run transient_shaper_lib.ipynb\n",
    "\n",
    "SAMPLE_LENGTH = 10\n",
    "\n",
    "def read_audio_files(directory):\n",
    "  \"\"\"\n",
    "  Reads all audio files from a directory and returns their data with file name labels.\n",
    "\n",
    "  Args:\n",
    "      directory: The directory path (string).\n",
    "\n",
    "  Returns:\n",
    "      A list of tuples, where each tuple contains:\n",
    "          - The audio data as a NumPy array.\n",
    "          - The filename (without extension).\n",
    "  \"\"\"\n",
    "\n",
    "  audio_data_list = []\n",
    "  for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".wav\"):  # Check for .wav files\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        sample_rate, audio_data = sp.io.wavfile.read(filepath)\n",
    "        try:\n",
    "          audio_data = audio_data[:, 0]\n",
    "        except:\n",
    "          pass\n",
    "        n_bits = 32  # Assuming 32-bit audio\n",
    "        audio_data = audio_data / (2**(n_bits - 1))  # Adjust range to -1 to 1 \n",
    "        audio_data /= np.abs(np.max(audio_data))  # Safer normalization\n",
    "        audio_data = audio_data[: sample_rate * SAMPLE_LENGTH]\n",
    "        label = os.path.splitext(filename)[0]  # Extract filename without extension\n",
    "        audio_data_list.append((audio_data, label, sample_rate))\n",
    "\n",
    "  return audio_data_list\n",
    "\n",
    "audio_data_with_labels = read_audio_files(os.getcwd())\n",
    "\n",
    "print(\"Audio data and labels:\")\n",
    "for audio_data, label, sample_rate in audio_data_with_labels:\n",
    "  print(f\"- Label: {label}, Audio data shape: {audio_data.shape}, Sample rate: {sample_rate}\")\n",
    "\n",
    "FRAME_LEN = 1   # in s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 - 330744__alonnaallen__90s-beat-loop-140bpm\n",
      "93.53789592760181\n"
     ]
    }
   ],
   "source": [
    "# my_python_script.py\n",
    "from ctypes import *\n",
    "\n",
    "# Load the shared library\n",
    "lib = CDLL(\"./AFInC.so\")  # Adjust path accordingly\n",
    "\n",
    "# Set up the square function's argtypes and restype\n",
    "lib.BeatDetectionInit.argtypes = []\n",
    "lib.BeatDetectionInit.restype = None\n",
    "\n",
    "lib.AFInCAppend.argtypes = [c_double]\n",
    "lib.AFInCAppend.restype = None\n",
    "\n",
    "lib.AFInCProcess.argtypes = []\n",
    "lib.AFInCProcess.restype = None\n",
    "\n",
    "lib.getTempo.argtypes = []\n",
    "lib.getTempo.restype = c_double\n",
    "\n",
    "lib.BeatDetectionInit()\n",
    "\n",
    "print(audio_data_with_labels[10][1])\n",
    "for sample in audio_data_with_labels[10][0]:\n",
    "    lib.AFInCAppend(sample)\n",
    "\n",
    "lib.AFInCProcess()\n",
    "\n",
    "result = lib.getTempo()\n",
    "print(result)  # Output: 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $T_{1A}$ & $T_{2A}$\n",
    "$T_{1A}$ and $T_{2A}$ are the time constants describing the duration of attack ($T_1$) and release ($T_2$). In this case, we define $T_1$ to be the time it takes to rise from the first detected minimum in the smoothed envelope $x_e$ to the peak value in a frame. $x_e$ is derived from applying cascaded exponential envelope filters onto the audio signal. The parameters which produce these filters are listed below in code. $T_2$ is obtained by calculating the time between the frame's peak and the next detected minimum. After each $T_1$ and $T_2$ have been found per frame, a mean calculation breaks them down into one scalar value per audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Label: 1 - looperman-l-5151565-0354397-spicy-drums, Attack time (mean): 0.00964 s, Release time (mean): 0.09068 s\n",
      "- Label: 10 - 484656__yellowtree__gloomy-guitar-loop, Attack time (mean): 0.01117 s, Release time (mean): 0.02496 s\n",
      "- Label: 11 - Vocal A, Attack time (mean): 0.05912 s, Release time (mean): 0.05810 s\n",
      "- Label: 12 - Vocal B, Attack time (mean): 0.08676 s, Release time (mean): 0.09068 s\n",
      "- Label: 13 - 20240208_Eli Preiss - Alles (und nichts) ｜ A COLORS SHOW, Attack time (mean): 0.06098 s, Release time (mean): 0.08331 s\n",
      "- Label: 2 - looperman-l-2379402-0354276-aftershock-hard-trap-drums-x-808-x-percs-kb, Attack time (mean): 0.04213 s, Release time (mean): 0.07249 s\n",
      "- Label: 3 - looperman-l-3066414-0354301-boom-bap-classic-hip-hop-drums, Attack time (mean): 0.02308 s, Release time (mean): 0.09068 s\n",
      "- Label: 4 - 244392__insidebeat__hip-hop-3-mpc500, Attack time (mean): 0.03937 s, Release time (mean): 0.09068 s\n",
      "- Label: 5 - 345289__50fps__4-beat-14-upbeat, Attack time (mean): 0.00998 s, Release time (mean): 0.09068 s\n",
      "- Label: 6 - 367962__trngle__175bpm-db-drum-sequence, Attack time (mean): 0.09070 s, Release time (mean): 0.09068 s\n",
      "- Label: 7 - 330744__alonnaallen__90s-beat-loop-140bpm, Attack time (mean): 0.01438 s, Release time (mean): 0.09068 s\n",
      "- Label: 8 - 652462__yellowtree__midwest-clean-guitar, Attack time (mean): 0.07553 s, Release time (mean): 0.09068 s\n",
      "- Label: 9 - 584282__yellowtree__clean-guitar-loop, Attack time (mean): 0.04167 s, Release time (mean): 0.04166 s\n",
      "- Label: bass, Attack time (mean): 0.06746 s, Release time (mean): 0.05163 s\n",
      "- Label: congas_82_25_1, Attack time (mean): 0.01107 s, Release time (mean): 0.09068 s\n",
      "- Label: congas_82_25_5, Attack time (mean): 0.01007 s, Release time (mean): 0.09068 s\n",
      "- Label: shaker, Attack time (mean): 0.02356 s, Release time (mean): 0.09068 s\n",
      "- Label: single notes hoch, Attack time (mean): 0.07628 s, Release time (mean): 0.01952 s\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Constants for the envelope followers\n",
    "\"\"\"\n",
    "ENV_SMOOTH_ORDER = 4            # in n\n",
    "ENV_SMOOTH_ATTACK = 2           # in ms\n",
    "ENV_SMOOTH_RELEASE = 200        # in ms\n",
    "EXTREMA_SEARCH_INTERVAL = 4000  # in samples\n",
    "\n",
    "\"\"\"\n",
    "Apply the envelope followers onto a given signal.\n",
    "\"\"\"\n",
    "def getEnvelope(sig: np.ndarray, fs: int) -> np.ndarray:\n",
    "    order = 4\n",
    "    attack = 2\n",
    "    release = 200\n",
    "    smooth_fast = ExpSmooth(ENV_SMOOTH_ORDER)\n",
    "    smooth_fast.reset(fs)\n",
    "    smooth_fast.set_attack(ENV_SMOOTH_ATTACK)\n",
    "    smooth_fast.set_release(ENV_SMOOTH_RELEASE)\n",
    "    num_samples = len(sig)\n",
    "    env_smooth = np.zeros(num_samples)\n",
    "    for i, sample in enumerate(sig):\n",
    "        env_smooth[i] = smooth_fast.process(sample)\n",
    "    return env_smooth\n",
    "\n",
    "\"\"\"\n",
    "Get the index of the peak value of a given signal within a range of samples.\n",
    "\"\"\"\n",
    "def getIdxOfMax(sig: np.ndarray, from_idx: int, to_idx: int) -> int:\n",
    "    idx_max = from_idx\n",
    "    for i in range(from_idx, to_idx):\n",
    "        if(sig[i] > sig[idx_max]):\n",
    "            idx_max = i\n",
    "    return idx_max\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Get the index of the smallest value of a given signal within a range of samples.\n",
    "\"\"\"\n",
    "def getIdxOfMin(sig: np.ndarray, from_idx: int, to_idx: int) -> int:\n",
    "    idx_min = from_idx\n",
    "    for i in range(from_idx, to_idx):\n",
    "        if(sig[i] < sig[idx_min]):\n",
    "            idx_min = i\n",
    "    return idx_min\n",
    "\n",
    "\"\"\"\n",
    "Calculate T_1 and T_2 per frame and return them as both mean values and one value per frame.\n",
    "\"\"\"\n",
    "def getTA(sig: np.ndarray, search_interval: int, fs: int) -> int:\n",
    "    T1As = []\n",
    "    T2As = []\n",
    "    num_samples = len(sig)\n",
    "    frames = num_samples // (FRAME_LEN * fs) # ignore residual samples which don't form a full frame\n",
    "    for i in range(0, frames):\n",
    "        l_bound = i*fs\n",
    "        u_bound = (i+1)*fs-1\n",
    "        idx_max = getIdxOfMax(sig, l_bound, u_bound)\n",
    "        if idx_max < search_interval:\n",
    "            start = l_bound\n",
    "        else:\n",
    "            start = idx_max - search_interval\n",
    "        idx_min_pre = getIdxOfMin(sig, start, idx_max)\n",
    "\n",
    "        if idx_max + search_interval > u_bound:\n",
    "            stop = u_bound\n",
    "        else:\n",
    "            stop = idx_max + search_interval\n",
    "        idx_min_post = getIdxOfMin(env_smooth, idx_max, stop)\n",
    "        T1As.append((idx_max - idx_min_pre) / fs)\n",
    "        T2As.append((idx_min_post - idx_max) / fs)\n",
    "    T1A = np.sum(np.asarray(T1As))\n",
    "    T2A = np.sum(np.asarray(T2As))\n",
    "    return T1A / frames, T1As, T2A / frames, T2A\n",
    "\n",
    "for audio_data, label, sample_rate in audio_data_with_labels:\n",
    "  env_smooth = getEnvelope(audio_data, sample_rate)\n",
    "  T1A, T1As, T2A, T2As = getTA(env_smooth, EXTREMA_SEARCH_INTERVAL, sample_rate)\n",
    "  print(f\"- Label: {label}, Attack time (mean): {T1A:.5f} s, Release time (mean): {T2A:.5f} s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $G_{1H}$ & $G_{2H}$\n",
    "$G_{1H}$ and $G_{2H}$ represent the given gain value for the attack or release control voltage in the AI-TD. This is a human parameter and can't be derived from the signal, as it is purely determined by taste, hence the $H$ for \"human\". In the embedded program, this value is derived from the position of potentiometers that the user dialed in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $F_e$\n",
    "Tonality. Describes how \"tonal\" audio is. Right now, we treat this feature as the NOT percentage of spectral flatness, meaning a tonality of 0.3 for a signal with a spectral flatness of 0.7.\n",
    "\n",
    "Other ideas include:\n",
    "- [link](https://community.sw.siemens.com/s/article/Tonality) for definitions\n",
    "- [link](https://github.com/cocosci/pam-nac) for a python implementation (looks messy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Label: 1 - looperman-l-5151565-0354397-spicy-drums, Spectral Flattness: -41.88\n",
      "- Label: 10 - 484656__yellowtree__gloomy-guitar-loop, Spectral Flattness: -70.72\n",
      "- Label: 11 - Vocal A, Spectral Flattness: -48.97\n",
      "- Label: 12 - Vocal B, Spectral Flattness: -56.01\n",
      "- Label: 13 - 20240208_Eli Preiss - Alles (und nichts) ｜ A COLORS SHOW, Spectral Flattness: -82.33\n",
      "- Label: 2 - looperman-l-2379402-0354276-aftershock-hard-trap-drums-x-808-x-percs-kb, Spectral Flattness: -67.40\n",
      "- Label: 3 - looperman-l-3066414-0354301-boom-bap-classic-hip-hop-drums, Spectral Flattness: -59.15\n",
      "- Label: 4 - 244392__insidebeat__hip-hop-3-mpc500, Spectral Flattness: -50.30\n",
      "- Label: 5 - 345289__50fps__4-beat-14-upbeat, Spectral Flattness: -42.75\n",
      "- Label: 6 - 367962__trngle__175bpm-db-drum-sequence, Spectral Flattness: -14.62\n",
      "- Label: 7 - 330744__alonnaallen__90s-beat-loop-140bpm, Spectral Flattness: -33.79\n",
      "- Label: 8 - 652462__yellowtree__midwest-clean-guitar, Spectral Flattness: -87.09\n",
      "- Label: 9 - 584282__yellowtree__clean-guitar-loop, Spectral Flattness: -87.40\n",
      "- Label: bass, Spectral Flattness: -84.43\n",
      "- Label: congas_82_25_1, Spectral Flattness: -54.36\n",
      "- Label: congas_82_25_5, Spectral Flattness: -69.83\n",
      "- Label: shaker, Spectral Flattness: -18.22\n",
      "- Label: single notes hoch, Spectral Flattness: -82.37\n"
     ]
    }
   ],
   "source": [
    "#Todo: Inspect Interative rolling scheiss teil\n",
    "\n",
    "def getSpectralFlatness(sig, fs: int):\n",
    "    spectrum = np.fft.fft(sig)\n",
    "    power_spectrum = np.abs(spectrum)**2\n",
    "    arithmetic_mean = 0\n",
    "    sum_of_logs = 0\n",
    "\n",
    "    for i in range(len(power_spectrum)):\n",
    "        arithmetic_mean += power_spectrum[i]\n",
    "        if power_spectrum[i] > 0:  # Avoid log(0)\n",
    "            sum_of_logs += np.log(power_spectrum[i])\n",
    "\n",
    "    arithmetic_mean /= len(power_spectrum)\n",
    "    geometric_mean = np.exp(sum_of_logs / len(power_spectrum))\n",
    "\n",
    "    if arithmetic_mean == 0:\n",
    "        return np.inf\n",
    "\n",
    "    flatness = geometric_mean / arithmetic_mean\n",
    "    return 20 * np.log10(flatness)\n",
    "\n",
    "for audio_data, label, sample_rate in audio_data_with_labels:\n",
    "  print(f\"- Label: {label}, Spectral Flattness: {getSpectralFlatness(audio_data, sample_rate):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $C_f$\n",
    "Calculate the dynamic variation of a signal. Idea: Combine the amount of peaks and valleys and their deltas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Label: 1 - looperman-l-5151565-0354397-spicy-drums, Crest Factor: 7.36\n",
      "- Label: 10 - 484656__yellowtree__gloomy-guitar-loop, Crest Factor: 3.85\n",
      "- Label: 11 - Vocal A, Crest Factor: 3.71\n",
      "- Label: 12 - Vocal B, Crest Factor: 4.02\n",
      "- Label: 13 - 20240208_Eli Preiss - Alles (und nichts) ｜ A COLORS SHOW, Crest Factor: 4.09\n",
      "- Label: 2 - looperman-l-2379402-0354276-aftershock-hard-trap-drums-x-808-x-percs-kb, Crest Factor: 1.86\n",
      "- Label: 3 - looperman-l-3066414-0354301-boom-bap-classic-hip-hop-drums, Crest Factor: 4.66\n",
      "- Label: 4 - 244392__insidebeat__hip-hop-3-mpc500, Crest Factor: 6.98\n",
      "- Label: 5 - 345289__50fps__4-beat-14-upbeat, Crest Factor: 3.54\n",
      "- Label: 6 - 367962__trngle__175bpm-db-drum-sequence, Crest Factor: 4.54\n",
      "- Label: 7 - 330744__alonnaallen__90s-beat-loop-140bpm, Crest Factor: 6.30\n",
      "- Label: 8 - 652462__yellowtree__midwest-clean-guitar, Crest Factor: 3.78\n",
      "- Label: 9 - 584282__yellowtree__clean-guitar-loop, Crest Factor: 6.10\n",
      "- Label: bass, Crest Factor: 4.71\n",
      "- Label: congas_82_25_1, Crest Factor: 9.77\n",
      "- Label: congas_82_25_5, Crest Factor: 7.03\n",
      "- Label: shaker, Crest Factor: 14.35\n",
      "- Label: single notes hoch, Crest Factor: 2.69\n"
     ]
    }
   ],
   "source": [
    "def calculate_crest_factor(buffer, fs: int):\n",
    "    \"\"\"Calculates the crest factor of a given audio buffer.\n",
    "\n",
    "    Args:\n",
    "        buffer: A list or array containing audio samples.\n",
    "\n",
    "    Returns:\n",
    "        The crest factor as a float.\n",
    "    \"\"\"\n",
    "\n",
    "    max_sample = 0.0\n",
    "    rms = 0.0\n",
    "    n_samples = len(buffer)\n",
    "\n",
    "    # Find the maximum absolute sample value\n",
    "    for i in range(n_samples):\n",
    "        abs_sample = abs(buffer[i])\n",
    "        if abs_sample > max_sample:\n",
    "            max_sample = abs_sample\n",
    "\n",
    "    # Calculate RMS (Root Mean Square)\n",
    "    for i in range(n_samples):\n",
    "        rms += buffer[i] * buffer[i]\n",
    "    rms = rms / n_samples  # Divide by number of samples\n",
    "    rms = pow(rms, 0.5)   # Take the square root\n",
    "\n",
    "    # Avoid division by zero\n",
    "    if rms == 0.0:\n",
    "        return 0.0\n",
    "\n",
    "    crest_factor = max_sample / rms\n",
    "    return crest_factor\n",
    "\n",
    "for audio_data, label, sample_rate in audio_data_with_labels:\n",
    "  print(f\"- Label: {label}, Crest Factor: {calculate_crest_factor(audio_data, sample_rate):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Label: 1 - looperman-l-5151565-0354397-spicy-drums, Spectral Centroid: 3353.50\n",
      "- Label: 10 - 484656__yellowtree__gloomy-guitar-loop, Spectral Centroid: 1807.38\n",
      "- Label: 11 - Vocal A, Spectral Centroid: 4500.27\n",
      "- Label: 12 - Vocal B, Spectral Centroid: 4030.68\n",
      "- Label: 13 - 20240208_Eli Preiss - Alles (und nichts) ｜ A COLORS SHOW, Spectral Centroid: 1301.27\n",
      "- Label: 2 - looperman-l-2379402-0354276-aftershock-hard-trap-drums-x-808-x-percs-kb, Spectral Centroid: 3538.25\n",
      "- Label: 3 - looperman-l-3066414-0354301-boom-bap-classic-hip-hop-drums, Spectral Centroid: 2693.29\n",
      "- Label: 4 - 244392__insidebeat__hip-hop-3-mpc500, Spectral Centroid: 2634.09\n",
      "- Label: 5 - 345289__50fps__4-beat-14-upbeat, Spectral Centroid: 5944.02\n",
      "- Label: 6 - 367962__trngle__175bpm-db-drum-sequence, Spectral Centroid: 8200.64\n",
      "- Label: 7 - 330744__alonnaallen__90s-beat-loop-140bpm, Spectral Centroid: 5415.12\n",
      "- Label: 8 - 652462__yellowtree__midwest-clean-guitar, Spectral Centroid: 1545.31\n",
      "- Label: 9 - 584282__yellowtree__clean-guitar-loop, Spectral Centroid: 2329.49\n",
      "- Label: bass, Spectral Centroid: 810.00\n",
      "- Label: congas_82_25_1, Spectral Centroid: 2932.12\n",
      "- Label: congas_82_25_5, Spectral Centroid: 2001.16\n",
      "- Label: shaker, Spectral Centroid: 8421.58\n",
      "- Label: single notes hoch, Spectral Centroid: 1685.35\n"
     ]
    }
   ],
   "source": [
    "def calculate_spectral_centroid(buffer, fs):\n",
    "  \"\"\"Calculates the spectral centroid of a given audio buffer.\n",
    "\n",
    "  Args:\n",
    "      buffer: A list or array containing audio samples.\n",
    "      fs: The sampling rate of the audio data (in Hz).\n",
    "\n",
    "  Returns:\n",
    "      The spectral centroid as a float (in Hz).\n",
    "  \"\"\"\n",
    "\n",
    "  fft = np.fft.rfft(buffer)\n",
    "  fft_abs = np.abs(fft)\n",
    "  fft_freqs = np.fft.rfftfreq(len(buffer), d=1/fs)  # Keep only positive frequencies\n",
    "\n",
    "  # Calculate weighted mean frequency\n",
    "  numerator = 0.0\n",
    "  denominator = 0.0\n",
    "  for i in range(len(fft_freqs)):\n",
    "      numerator += fft_freqs[i] * fft_abs[i]\n",
    "      denominator += fft_abs[i]\n",
    "\n",
    "  # Avoid division by zero\n",
    "  if denominator == 0.0:\n",
    "      return 0.0\n",
    "\n",
    "  centroid = numerator / denominator\n",
    "  return centroid\n",
    "\n",
    "for audio_data, label, sample_rate in audio_data_with_labels:\n",
    "  print(f\"- Label: {label}, Spectral Centroid: {calculate_spectral_centroid(audio_data, sample_rate):.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
