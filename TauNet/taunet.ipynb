{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version 2.12.0\n"
     ]
    }
   ],
   "source": [
    "# file related\n",
    "import os\n",
    "from os.path import join\n",
    "\n",
    "# machine learning\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import librosa\n",
    "import import_ipynb\n",
    "from IPython.display import Audio as play_audio\n",
    "import scipy as sp\n",
    "import matplotlib.patches as patches\n",
    "import taunet_utils\n",
    "%run transient_shaper_lib.ipynb\n",
    "\n",
    "print(f\"TF version {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: (123.9669, 0.012, 0.2251, 15648, 0.7536, 10, 1, 1, 1, -2097225378, 0.6738, 0.8758, 550.0, 350.0) -> (360.5123, 1144.7427)\n",
      "10: (159.0106, 0.0131, 0.2123, 2440, 0.8535, 10, 1, 1, 1, 0, 0.3157, 0.8187, 550.0, 350.0) -> (330.558, 1814.8958)\n",
      "11: (117.4935, 0.0408, 0.31, 7351, 0.7748, 10, 1, 1, 1, 546576167, 0.7365, 0.7567, 550.0, 350.0) -> (302.5441, 430.5534)\n",
      "12: (172.4138, 0.3676, 0.4617, 15840, 1.569, 10, 1, 1, 1, 102581079, 0.7287, 0.8574, 550.0, 350.0) -> (70.1614, 1192.9986)\n",
      "13: (156.7944, 0.0098, 0.1759, 3139, 0.859, 10, 1, 1, 1, 78035367, 0.109, 0.9997, 550.0, 350.0) -> (283.9686, 1571.1926)\n",
      "14: (152.5424, 0.0422, 0.245, 2145, 1.1746, 10, 1, 1, 1, 0, 0.6313, 0.2773, 550.0, 350.0) -> (281.9786, 461.7476)\n",
      "15: (143.77, 1.4763, 0.1339, 2145, 2.2429, 10, 1, 1, 1, -1248480519, 0.5662, 0.8151, 550.0, 350.0) -> (206.762, 1754.8867)\n",
      "16: (127.8409, 0.0328, 0.2358, 2134, 0.8128, 10, 1, 1, 1, 1320852491, 0.6062, 0.2058, 550.0, 350.0) -> (499.6292, 320.9579)\n",
      "17: (140.1869, 0.0419, 0.1801, 9275, 1.0342, 10, 1, 1, 1, 0, 0.2384, 0.8137, 550.0, 350.0) -> (72.4846, 1072.764)\n",
      "18: (182.9268, 0.0413, 0.1093, 8242, 0.8375, 10, 1, 1, 1, 1030715427, 0.9379, 0.7991, 550.0, 350.0) -> (238.3422, 263.6662)\n",
      "19: (160.7143, 0.0559, 0.1917, 11227, 1.0434, 10, 1, 1, 1, 195994920, 0.1, 0.9998, 550.0, 350.0) -> (257.3969, 1804.9393)\n",
      "2: (153.0612, 0.0322, 0.1695, 10716, 0.8286, 10, 1, 1, 1, 792549982, 0.7384, 0.2437, 550.0, 350.0) -> (499.9752, 374.6085)\n",
      "20: (189.0756, 0.0168, 0.4584, 5347, 0.9867, 10, 1, 1, 1, 0, 0.9252, 0.0, 550.0, 350.0) -> (112.2112, 651.2755)\n",
      "21: (150.0, 0.015, 0.1608, 12284, 0.8636, 10, 1, 1, 1, 367950548, 0.5384, 0.8216, 550.0, 350.0) -> (429.106, 423.9346)\n",
      "22: (147.0588, 0.0252, 0.1561, 2562, 1.3738, 10, 1, 1, 1, -1834691720, 0.5007, 0.2, 550.0, 350.0) -> (271.4743, 973.7288)\n",
      "23: (150.0, 0.0574, 0.1927, 8812, 0.6881, 10, 1, 1, 1, 344125193, 0.6167, 0.2, 550.0, 350.0) -> (421.4269, 1265.6743)\n",
      "24: (150.0, 0.0188, 0.1594, 12988, 0.8422, 10, 1, 1, 1, 955458169, 0.5016, 0.8097, 550.0, 350.0) -> (71.7921, 330.5029)\n",
      "25: (140.1869, 0.0539, 0.2009, 7704, 0.8947, 10, 1, 1, 1, 0, 0.4924, 0.8547, 550.0, 350.0) -> (152.5522, 2234.698)\n",
      "26: (175.7812, 0.0405, 0.1577, 7608, 0.6698, 10, 1, 1, 1, 190016378, 0.7254, 0.55, 550.0, 350.0) -> (472.6673, 448.8248)\n",
      "27: (175.7812, 0.0319, 0.272, 6159, 0.6361, 10, 1, 1, 1, 443174500, 0.2685, 0.7946, 550.0, 350.0) -> (302.805, 432.6586)\n",
      "28: (110.2941, 0.0204, 0.2344, 7598, 0.984, 10, 1, 1, 1, 623134444, 0.2503, 0.81, 550.0, 350.0) -> (302.8251, 358.3355)\n",
      "29: (120.0, 0.0467, 0.4485, 22029, 1.5532, 10, 1, 1, 1, 1239754948, 0.2941, 0.9105, 550.0, 350.0) -> (58.7472, 2487.4433)\n",
      "3: (171.1027, 0.0236, 0.3093, 6131, 0.8149, 10, 1, 1, 1, 0, 0.2224, 0.9991, 550.0, 350.0) -> (22.6204, 1932.1606)\n",
      "30: (120.6434, 0.0323, 0.2838, 11913, 0.7958, 10, 1, 1, 1, 0, 0.5815, 0.1677, 550.0, 350.0) -> (371.8012, 402.8134)\n",
      "31: (166.6667, 0.0224, 0.1591, 6098, 0.5228, 10, 1, 1, 1, 0, 0.5916, 0.324, 550.0, 350.0) -> (499.9876, 1742.1198)\n",
      "32: (153.0612, 0.0201, 0.2427, 11483, 0.6263, 10, 1, 1, 1, 1271146919, 0.3395, 0.766, 550.0, 350.0) -> (499.6786, 1684.4062)\n",
      "33: (115.3846, 0.0442, 0.1896, 13033, 0.7633, 10, 1, 1, 1, 0, 0.6804, 0.2354, 550.0, 350.0) -> (338.8656, 2195.2792)\n",
      "34: (152.027, 0.0098, 0.0514, 7365, 0.712, 10, 1, 1, 1, 647517111, 0.6663, 0.9598, 550.0, 350.0) -> (134.6054, 732.4129)\n",
      "35: (127.1186, 0.0327, 0.2024, 10029, 0.6965, 10, 1, 1, 1, 0, 0.79, 0.7839, 550.0, 350.0) -> (435.8906, 1932.2294)\n",
      "36: (140.1869, 0.0391, 0.2229, 10214, 0.8226, 10, 1, 1, 1, -729645567, 0.2839, 0.7826, 550.0, 350.0) -> (146.9939, 1507.6749)\n",
      "37: (169.8113, 0.0254, 0.1721, 13557, 0.9161, 10, 1, 1, 1, 0, 0.2839, 0.2469, 550.0, 350.0) -> (147.12, 392.7355)\n",
      "38: (116.2791, 0.0121, 0.2267, 2785, 1.841, 10, 1, 1, 1, 0, 0.9343, 0.2477, 550.0, 350.0) -> (223.2471, 879.385)\n",
      "39: (135.1351, 0.0378, 0.1944, 6473, 0.7804, 10, 1, 1, 1, 0, 0.7667, 0.9138, 550.0, 350.0) -> (101.5045, 829.8327)\n",
      "4: (181.4516, 0.0295, 0.312, 7388, 0.6837, 10, 1, 1, 1, 0, 0.6711, 0.8347, 550.0, 350.0) -> (149.4464, 1335.9675)\n",
      "40: (114.7959, 0.0193, 0.1472, 10727, 0.5565, 10, 1, 1, 1, 288785892, 0.1961, 0.9731, 550.0, 350.0) -> (52.7942, 812.402)\n",
      "41: (138.8889, 0.013, 0.1897, 13772, 0.6406, 10, 1, 1, 1, 699759816, 0.8142, 0.8705, 550.0, 350.0) -> (221.9869, 2306.58)\n",
      "42: (184.4262, 0.0133, 0.1206, 12656, 0.8213, 10, 1, 1, 1, -539618441, 0.5115, 0.9999, 550.0, 350.0) -> (43.8154, 627.4901)\n",
      "43: (173.0769, 0.0457, 0.2016, 5465, 0.7821, 10, 1, 1, 1, -135648044, 0.2125, 0.9111, 550.0, 350.0) -> (224.9704, 305.5782)\n",
      "44: (182.9268, 0.0429, 0.1394, 7842, 0.7851, 10, 1, 1, 1, 0, 0.6257, 0.9111, 550.0, 350.0) -> (53.1591, 597.468)\n",
      "45: (127.1186, 0.064, 0.1965, 6893, 1.4126, 10, 1, 1, 1, 0, 0.6312, 0.3742, 550.0, 350.0) -> (257.4438, 150.3251)\n",
      "46: (119.0476, 0.0214, 0.1387, 8967, 0.9583, 10, 1, 1, 1, 0, 0.1037, 0.3663, 550.0, 350.0) -> (315.5311, 219.7976)\n",
      "47: (159.0106, 0.0059, 0.2267, 3745, 0.6353, 10, 1, 1, 1, -1338698710, 0.1048, 0.7492, 550.0, 350.0) -> (316.7472, 861.2394)\n",
      "48: (188.2845, 0.0394, 0.1795, 8759, 1.3367, 10, 1, 1, 1, -785582452, 0.4944, 0.9, 550.0, 350.0) -> (316.8393, 530.1154)\n",
      "49: (140.1869, 0.0295, 0.5174, 8121, 0.6854, 10, 1, 1, 1, 0, 0.2449, 0.9615, 550.0, 350.0) -> (317.439, 644.2965)\n",
      "5: (108.6957, 0.0119, 0.2545, 14056, 0.7825, 10, 1, 1, 1, -882529423, 0.6149, 0.8181, 550.0, 350.0) -> (351.3529, 1696.3634)\n",
      "50: (167.2862, 0.0202, 0.1536, 10259, 0.9246, 10, 1, 1, 1, -1777035699, 0.6273, 0.8602, 550.0, 350.0) -> (115.6247, 1020.5743)\n",
      "51: (160.1423, 0.0215, 0.1547, 7594, 0.6082, 10, 1, 1, 1, 0, 0.1535, 0.2204, 550.0, 350.0) -> (335.4641, 475.4434)\n",
      "52: (160.1423, 0.0107, 0.1133, 2588, 0.8581, 10, 1, 1, 1, 679897429, 0.2779, 0.731, 550.0, 350.0) -> (348.9426, 714.1963)\n",
      "53: (138.0368, 0.0282, 0.1143, 14615, 0.8561, 10, 1, 1, 1, 2066522964, 0.2809, 0.7829, 550.0, 350.0) -> (59.8091, 1774.3952)\n",
      "54: (166.0517, 0.024, 0.1076, 10859, 0.4955, 10, 1, 1, 1, 25431435, 0.6411, 0.7838, 550.0, 350.0) -> (35.7718, 1777.6143)\n",
      "55: (122.9508, 0.0216, 0.1274, 7313, 0.6587, 10, 1, 1, 1, -1785165203, 0.5695, 0.7159, 550.0, 350.0) -> (499.9876, 2999.913)\n",
      "56: (120.3209, 0.0213, 0.1174, 6619, 0.6565, 10, 1, 1, 1, -614777962, 0.27, 0.7147, 550.0, 350.0) -> (152.9265, 2998.6086)\n",
      "57: (135.1351, 0.0232, 0.1209, 10485, 0.579, 10, 1, 1, 1, -1493132023, 0.287, 0.8795, 550.0, 350.0) -> (368.7665, 409.3572)\n",
      "58: (109.2233, 0.037, 0.4977, 3150, 1.2654, 10, 1, 1, 1, -319688086, 0.2181, 0.8451, 550.0, 350.0) -> (55.3032, 885.4696)\n",
      "59: (154.6392, 0.0136, 0.1331, 1518, 1.0106, 10, 1, 1, 1, 1569575209, 0.569, 0.7956, 550.0, 350.0) -> (153.894, 434.4418)\n",
      "6: (173.7452, 0.0087, 0.1529, 25353, 0.6055, 10, 1, 1, 1, 1288184134, 0.2, 0.9179, 550.0, 350.0) -> (91.6004, 2420.8156)\n",
      "7: (186.722, 0.0172, 0.3052, 18644, 0.8725, 10, 1, 1, 1, 0, 0.6255, 0.4053, 550.0, 350.0) -> (499.9876, 221.555)\n",
      "8: (199.115, 0.0269, 0.1894, 3541, 1.1604, 10, 1, 1, 1, -641464461, 0.6357, 0.3034, 550.0, 350.0) -> (470.3991, 217.7039)\n",
      "9: (119.6809, 0.0604, 0.4038, 3407, 1.3411, 10, 1, 1, 1, -757942753, 0.6341, 0.7424, 550.0, 350.0) -> (246.8427, 1787.1588)\n"
     ]
    }
   ],
   "source": [
    "def create_dataset(audio_dir, human_input_csv):\n",
    "    lib = taunet_utils.af_dsp_init(\"../src/af/AFInC.dll\")\n",
    "    audio_data = taunet_utils.read_audio_files(audio_dir)\n",
    "    human_data = pd.read_csv(human_input_csv)\n",
    "\n",
    "    input_data = dict()\n",
    "    output_data = dict()\n",
    "    \n",
    "    for audio, label, fs in audio_data:\n",
    "        lib.initAf()\n",
    "        lib.resetBuffer()\n",
    "        label = label.split()[0]\n",
    "        for sample in audio:\n",
    "            lib.AFInCAppend(sample)\n",
    "        lib.AFInCProcess()\n",
    "        \n",
    "        human_input = human_data[human_data['MEASUREMENT_ID'] == int(label)].iloc[0].to_dict()\n",
    "        human_input.pop(\"MEASUREMENT_ID\")\n",
    "        human_input.pop(\"SONG_ID\")\n",
    "        human_output = dict()\n",
    "        human_output[\"ATTACK_T1\"] = human_input.pop(\"ATTACK_T1\")\n",
    "        human_output[\"SUSTAIN_T1\"] = human_input.pop(\"SUSTAIN_T1\")\n",
    "        output_data[label] = tuple(human_output.values())\n",
    "        \n",
    "        input_data[label] = tuple(round(val, 4) for val in (\n",
    "            lib.afGetTempo(),\n",
    "            lib.afGetT1A() / fs,\n",
    "            lib.afGetT2A() / fs,\n",
    "            int(lib.afGetSpectralCentroid()),\n",
    "            lib.afGetSpectralFlatness(),\n",
    "            int(lib.afGetPBandL()),\n",
    "            int(lib.afGetPBandML()),\n",
    "            int(lib.afGetPBandMH()),\n",
    "            int(lib.afGetPBandH()),\n",
    "            lib.afGetCrestFactor()\n",
    "        ))\n",
    "        input_data[label] += tuple(human_input.values())\n",
    "    return input_data, output_data\n",
    "\n",
    "input_data, output_data = create_dataset(os.path.join(\"dataset\", \"audio\"), os.path.join(\"dataset\", \"human_input\", \"AITD_Dataset_Kristof_beta_1.csv\"))\n",
    "for d in input_data:\n",
    "    print(f\"{d}: {input_data[d]} -> {output_data[d]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 64)                960       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,722\n",
      "Trainable params: 3,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    # model.add(layers.LSTM(64, return_sequences=True))   # short term memory, useful if input data is related accross vectors\n",
    "    model.add(Dense(2)) # no activation (linear): continuous mapping of outputs (this is not a classification task!)\n",
    "    return model\n",
    "\n",
    "input_shape = (14,)\n",
    "model = create_model(input_shape)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 11700), started 0:10:50 ago. (Use '!kill 11700' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-78de368b00835bbe\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-78de368b00835bbe\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 580ms/step - loss: 114867617792.0000 - accuracy: 0.7027 - val_loss: 4027687424.0000 - val_accuracy: 0.3000\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 338ms/step - loss: 110603075584.0000 - accuracy: 0.7027 - val_loss: 3861800448.0000 - val_accuracy: 0.3000\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 341ms/step - loss: 105787047936.0000 - accuracy: 0.7027 - val_loss: 3698387456.0000 - val_accuracy: 0.3000\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 401ms/step - loss: 101431320576.0000 - accuracy: 0.7027 - val_loss: 3531942400.0000 - val_accuracy: 0.3000\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 287ms/step - loss: 96714817536.0000 - accuracy: 0.7027 - val_loss: 3637867264.0000 - val_accuracy: 0.3000\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 1s 512ms/step - loss: 99150282752.0000 - accuracy: 0.7027 - val_loss: 3350287872.0000 - val_accuracy: 0.3000\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 297ms/step - loss: 93040541696.0000 - accuracy: 0.7027 - val_loss: 3399460864.0000 - val_accuracy: 0.3000\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 94354038784.0000 - accuracy: 0.7027 - val_loss: 3398644224.0000 - val_accuracy: 0.3000\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 192ms/step - loss: 94415093760.0000 - accuracy: 0.7027 - val_loss: 3353750272.0000 - val_accuracy: 0.3000\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 273ms/step - loss: 93175390208.0000 - accuracy: 0.7027 - val_loss: 3272328704.0000 - val_accuracy: 0.3000\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 428ms/step - loss: 91094269952.0000 - accuracy: 0.7027 - val_loss: 3169140224.0000 - val_accuracy: 0.3000\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 248ms/step - loss: 88309489664.0000 - accuracy: 0.7027 - val_loss: 3070543872.0000 - val_accuracy: 0.3000\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 229ms/step - loss: 85265080320.0000 - accuracy: 0.7027 - val_loss: 2978609664.0000 - val_accuracy: 0.3000\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 238ms/step - loss: 82617638912.0000 - accuracy: 0.7027 - val_loss: 2889058816.0000 - val_accuracy: 0.3000\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 79648808960.0000 - accuracy: 0.7027 - val_loss: 2796329472.0000 - val_accuracy: 0.3000\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 201ms/step - loss: 76935856128.0000 - accuracy: 0.7027 - val_loss: 2695874304.0000 - val_accuracy: 0.3000\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 236ms/step - loss: 73668255744.0000 - accuracy: 0.7027 - val_loss: 2586219264.0000 - val_accuracy: 0.3000\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 188ms/step - loss: 70490267648.0000 - accuracy: 0.7027 - val_loss: 2475369472.0000 - val_accuracy: 0.3000\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 173ms/step - loss: 67528179712.0000 - accuracy: 0.7027 - val_loss: 2375946752.0000 - val_accuracy: 0.3000\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 175ms/step - loss: 64809046016.0000 - accuracy: 0.7027 - val_loss: 2282471168.0000 - val_accuracy: 0.3000\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 200ms/step - loss: 62179233792.0000 - accuracy: 0.7027 - val_loss: 2183883264.0000 - val_accuracy: 0.3000\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 220ms/step - loss: 59775434752.0000 - accuracy: 0.7027 - val_loss: 2087345792.0000 - val_accuracy: 0.3000\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 57609592832.0000 - accuracy: 0.7027 - val_loss: 2000275456.0000 - val_accuracy: 0.3000\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 55237844992.0000 - accuracy: 0.7027 - val_loss: 1911210624.0000 - val_accuracy: 0.3000\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 198ms/step - loss: 53129822208.0000 - accuracy: 0.7027 - val_loss: 1824395520.0000 - val_accuracy: 0.3000\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 224ms/step - loss: 50943492096.0000 - accuracy: 0.7297 - val_loss: 1926657280.0000 - val_accuracy: 0.6000\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 202ms/step - loss: 53528240128.0000 - accuracy: 0.7838 - val_loss: 1730520064.0000 - val_accuracy: 0.5000\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 231ms/step - loss: 48804765696.0000 - accuracy: 0.7027 - val_loss: 1729098752.0000 - val_accuracy: 0.3000\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 211ms/step - loss: 48830832640.0000 - accuracy: 0.7027 - val_loss: 1715591936.0000 - val_accuracy: 0.3000\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 48426471424.0000 - accuracy: 0.7027 - val_loss: 1688764032.0000 - val_accuracy: 0.3000\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 244ms/step - loss: 47607209984.0000 - accuracy: 0.7027 - val_loss: 1644698880.0000 - val_accuracy: 0.3000\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 187ms/step - loss: 46375145472.0000 - accuracy: 0.7027 - val_loss: 1593361792.0000 - val_accuracy: 0.6000\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 167ms/step - loss: 44886122496.0000 - accuracy: 0.8108 - val_loss: 1543378560.0000 - val_accuracy: 0.6000\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 177ms/step - loss: 43472707584.0000 - accuracy: 0.7568 - val_loss: 1497691008.0000 - val_accuracy: 0.3000\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 203ms/step - loss: 42022588416.0000 - accuracy: 0.7027 - val_loss: 1457042688.0000 - val_accuracy: 0.3000\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 187ms/step - loss: 40753307648.0000 - accuracy: 0.7027 - val_loss: 1416605696.0000 - val_accuracy: 0.3000\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 194ms/step - loss: 39504879616.0000 - accuracy: 0.7027 - val_loss: 1369203968.0000 - val_accuracy: 0.3000\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 179ms/step - loss: 38147493888.0000 - accuracy: 0.7027 - val_loss: 1322195840.0000 - val_accuracy: 0.3000\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 189ms/step - loss: 36817477632.0000 - accuracy: 0.7027 - val_loss: 1273573888.0000 - val_accuracy: 0.3000\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 218ms/step - loss: 35565228032.0000 - accuracy: 0.7027 - val_loss: 1328564480.0000 - val_accuracy: 0.3000\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 239ms/step - loss: 36494557184.0000 - accuracy: 0.7027 - val_loss: 1201553408.0000 - val_accuracy: 0.3000\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 203ms/step - loss: 33676335104.0000 - accuracy: 0.7027 - val_loss: 1178744448.0000 - val_accuracy: 0.3000\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 33029154816.0000 - accuracy: 0.7027 - val_loss: 1148435328.0000 - val_accuracy: 0.3000\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 199ms/step - loss: 32123033600.0000 - accuracy: 0.7027 - val_loss: 1108484224.0000 - val_accuracy: 0.3000\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 354ms/step - loss: 31174078464.0000 - accuracy: 0.7027 - val_loss: 1084441216.0000 - val_accuracy: 0.3000\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 227ms/step - loss: 30187231232.0000 - accuracy: 0.7027 - val_loss: 1040788288.0000 - val_accuracy: 0.3000\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 173ms/step - loss: 29133330432.0000 - accuracy: 0.7027 - val_loss: 1010848896.0000 - val_accuracy: 0.3000\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 171ms/step - loss: 28262055936.0000 - accuracy: 0.7027 - val_loss: 980849792.0000 - val_accuracy: 0.3000\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 27373752320.0000 - accuracy: 0.7027 - val_loss: 953161216.0000 - val_accuracy: 0.3000\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 26468470784.0000 - accuracy: 0.7027 - val_loss: 924429120.0000 - val_accuracy: 0.3000\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 199ms/step - loss: 25768181760.0000 - accuracy: 0.7027 - val_loss: 899473280.0000 - val_accuracy: 0.3000\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 179ms/step - loss: 24955480064.0000 - accuracy: 0.7027 - val_loss: 877842240.0000 - val_accuracy: 0.3000\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 198ms/step - loss: 24405927936.0000 - accuracy: 0.7027 - val_loss: 854769536.0000 - val_accuracy: 0.3000\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 202ms/step - loss: 23825590272.0000 - accuracy: 0.7027 - val_loss: 829835584.0000 - val_accuracy: 0.3000\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 191ms/step - loss: 23028002816.0000 - accuracy: 0.7027 - val_loss: 800164992.0000 - val_accuracy: 0.3000\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 186ms/step - loss: 22340769792.0000 - accuracy: 0.7027 - val_loss: 809004992.0000 - val_accuracy: 0.3000\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 196ms/step - loss: 22552604672.0000 - accuracy: 0.7027 - val_loss: 757468288.0000 - val_accuracy: 0.3000\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 198ms/step - loss: 21226672128.0000 - accuracy: 0.7027 - val_loss: 743712576.0000 - val_accuracy: 0.3000\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 213ms/step - loss: 20886820864.0000 - accuracy: 0.7027 - val_loss: 724600704.0000 - val_accuracy: 0.3000\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 223ms/step - loss: 20481226752.0000 - accuracy: 0.7027 - val_loss: 701388928.0000 - val_accuracy: 0.3000\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 172ms/step - loss: 19785211904.0000 - accuracy: 0.7027 - val_loss: 676068800.0000 - val_accuracy: 0.3000\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 180ms/step - loss: 19143714816.0000 - accuracy: 0.7027 - val_loss: 649496384.0000 - val_accuracy: 0.3000\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 177ms/step - loss: 18448732160.0000 - accuracy: 0.7027 - val_loss: 623935936.0000 - val_accuracy: 0.3000\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 17709709312.0000 - accuracy: 0.7027 - val_loss: 599292992.0000 - val_accuracy: 0.3000\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 199ms/step - loss: 17044838400.0000 - accuracy: 0.7027 - val_loss: 604126080.0000 - val_accuracy: 0.3000\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 193ms/step - loss: 17140853760.0000 - accuracy: 0.7027 - val_loss: 567120768.0000 - val_accuracy: 0.3000\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 203ms/step - loss: 16173403136.0000 - accuracy: 0.7027 - val_loss: 557260480.0000 - val_accuracy: 0.3000\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 189ms/step - loss: 15896213504.0000 - accuracy: 0.7027 - val_loss: 544992064.0000 - val_accuracy: 0.3000\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 15530405888.0000 - accuracy: 0.7027 - val_loss: 530246496.0000 - val_accuracy: 0.3000\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 200ms/step - loss: 15095530496.0000 - accuracy: 0.7027 - val_loss: 513220512.0000 - val_accuracy: 0.3000\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 187ms/step - loss: 14620323840.0000 - accuracy: 0.7027 - val_loss: 495432608.0000 - val_accuracy: 0.3000\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 238ms/step - loss: 14050331648.0000 - accuracy: 0.7027 - val_loss: 477639104.0000 - val_accuracy: 0.4000\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 192ms/step - loss: 13533483008.0000 - accuracy: 0.7027 - val_loss: 458678016.0000 - val_accuracy: 0.3000\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 239ms/step - loss: 13036732416.0000 - accuracy: 0.7027 - val_loss: 477844224.0000 - val_accuracy: 0.3000\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 235ms/step - loss: 13513493504.0000 - accuracy: 0.7027 - val_loss: 438944256.0000 - val_accuracy: 0.3000\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 172ms/step - loss: 12482172928.0000 - accuracy: 0.7027 - val_loss: 432312992.0000 - val_accuracy: 0.3000\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 177ms/step - loss: 12342351872.0000 - accuracy: 0.7027 - val_loss: 422076480.0000 - val_accuracy: 0.3000\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 193ms/step - loss: 12014740480.0000 - accuracy: 0.7027 - val_loss: 409366016.0000 - val_accuracy: 0.5000\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 215ms/step - loss: 11713390592.0000 - accuracy: 0.7568 - val_loss: 394260672.0000 - val_accuracy: 0.5000\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 227ms/step - loss: 11228374016.0000 - accuracy: 0.7297 - val_loss: 379039200.0000 - val_accuracy: 0.3000\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 196ms/step - loss: 10784784384.0000 - accuracy: 0.7027 - val_loss: 363138752.0000 - val_accuracy: 0.3000\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 204ms/step - loss: 10365282304.0000 - accuracy: 0.7027 - val_loss: 348206848.0000 - val_accuracy: 0.3000\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 206ms/step - loss: 9856541696.0000 - accuracy: 0.7027 - val_loss: 333923424.0000 - val_accuracy: 0.3000\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 167ms/step - loss: 9518783488.0000 - accuracy: 0.7027 - val_loss: 322419968.0000 - val_accuracy: 0.3000\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 187ms/step - loss: 9105961984.0000 - accuracy: 0.7027 - val_loss: 314069952.0000 - val_accuracy: 0.3000\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 347ms/step - loss: 8916506624.0000 - accuracy: 0.7027 - val_loss: 305805152.0000 - val_accuracy: 0.3000\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 8647470080.0000 - accuracy: 0.7027 - val_loss: 295813376.0000 - val_accuracy: 0.3000\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 221ms/step - loss: 8379798016.0000 - accuracy: 0.7027 - val_loss: 283655936.0000 - val_accuracy: 0.3000\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 176ms/step - loss: 8046519808.0000 - accuracy: 0.7027 - val_loss: 271672256.0000 - val_accuracy: 0.3000\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 177ms/step - loss: 7631952384.0000 - accuracy: 0.7027 - val_loss: 259242320.0000 - val_accuracy: 0.3000\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 199ms/step - loss: 7404619264.0000 - accuracy: 0.7027 - val_loss: 249053792.0000 - val_accuracy: 0.3000\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 7039282176.0000 - accuracy: 0.7027 - val_loss: 241064480.0000 - val_accuracy: 0.3000\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 6859982336.0000 - accuracy: 0.7027 - val_loss: 453119136.0000 - val_accuracy: 0.3000\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 194ms/step - loss: 6750654976.0000 - accuracy: 0.7027 - val_loss: 417731680.0000 - val_accuracy: 0.8000\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 188ms/step - loss: 6544233472.0000 - accuracy: 0.8919 - val_loss: 530559840.0000 - val_accuracy: 0.8000\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 186ms/step - loss: 6353010688.0000 - accuracy: 0.8919 - val_loss: 364682496.0000 - val_accuracy: 0.8000\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 251ms/step - loss: 6058337280.0000 - accuracy: 0.8919 - val_loss: 223331296.0000 - val_accuracy: 0.3000\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 232ms/step - loss: 5748418560.0000 - accuracy: 0.7027 - val_loss: 246778624.0000 - val_accuracy: 0.3000\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 5614182400.0000 - accuracy: 0.7027 - val_loss: 251078944.0000 - val_accuracy: 0.3000\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 247ms/step - loss: 5385956864.0000 - accuracy: 0.7027 - val_loss: 200539824.0000 - val_accuracy: 0.3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Final Train loss: 5291149824.0\n",
      "INFO:__main__:Final Train accuracy: 0.7027027010917664\n",
      "INFO:__main__:Final Validation loss: 200539824.0\n",
      "INFO:__main__:Final Validation accuracy: 0.30000001192092896\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Step 2: Combine Data\n",
    "combined_data = [(input_data[key], output_data[key]) for key in input_data.keys()]\n",
    "\n",
    "# Step 3: Split Data\n",
    "train_data, test_data = train_test_split(combined_data, test_size=0.2, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: TensorBoard Integration\n",
    "# Define TensorBoard log directory\n",
    "log_dir = \"logs/\"\n",
    "\n",
    "# Define TensorBoard callback\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Step 5: Logging\n",
    "def log_metrics(metrics_dict, prefix=\"\"):\n",
    "    for metric_name, metric_value in metrics_dict.items():\n",
    "        logger.info(f\"{prefix}{metric_name}: {metric_value}\")\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/ --port 6006\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    x=np.array([item[0] for item in train_data]),\n",
    "    y=np.array([item[1] for item in train_data]),\n",
    "    validation_data=(\n",
    "        np.array([item[0] for item in val_data]),\n",
    "        np.array([item[1] for item in val_data])\n",
    "    ),\n",
    "    epochs=100,\n",
    "    callbacks=[tensorboard_callback]\n",
    ")\n",
    "\n",
    "# Log metrics after training\n",
    "train_metrics = model.evaluate(\n",
    "    np.array([item[0] for item in train_data]),\n",
    "    np.array([item[1] for item in train_data]),\n",
    "    verbose=0\n",
    ")\n",
    "val_metrics = model.evaluate(\n",
    "    np.array([item[0] for item in val_data]),\n",
    "    np.array([item[1] for item in val_data]),\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "log_metrics({f\"Train {metric_name}\": metric_value for metric_name, metric_value in zip(model.metrics_names, train_metrics)}, \"Final \")\n",
    "log_metrics({f\"Validation {metric_name}\": metric_value for metric_name, metric_value in zip(model.metrics_names, val_metrics)}, \"Final \")\n",
    "\n",
    "model.save(\"taunet.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
